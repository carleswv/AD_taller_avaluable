---
title: "Taller evaluado de repaso para el Primer Parcial"
subtitle: "20582- Análisis de Datos para el GMAT"
date: today
author: "Carles Westendorf Vidal"
format:
  html:
    theme: lumen
    toc: true
    toc-depth: 3
Rendering:
    embed-resources: true
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

```{r, echo=FALSE}
library(tidyverse)
library(readr)
```


# RESUMEN
Estudiaremos como varía el tiempo dedicado a las pantallas (y redes sociales) entre los distintos rangos de edad y su posible relación con las actividades programadas como puede ser entrenar algun deporte, la lectura o las extraescolares en niños.


## OBJETIVOS
Queremos ver que los distintos habitos no están correlacionados (porque nuestros datos son aleatorios).

### METODOLOGÍA
Usaremos herramientas de analisis multivariante, en particular nos apoyaremos en la normalidad multivariante. También modelarizaremos por multinomiales y por regresiones multiples.


## RESULTADOS
Hay bastante redundancia en los datos, estan bien repartidos y, pese a todo esto, podemos decir que las medias de los datos cuantitativos es distinto para gente con distintas prioridades.



# PLANTEAMIENTO
Creemos unos datos con los que trabajar a partir de una normal multivariante de media $\mu=(0.7,0.66,0.51,6.5)$ y matriz de covarianzas:
$$\Sigma = 
\begin{pmatrix}
0.3 & 0.08 & 0.05 & 0.05 \\
0.09 & 0.28 & 0.03 & 0.01 \\
0.08 & 0.005 &  0.32 & 0.01 \\
0.08 & 0.38 & 0.49 & 2
\end{pmatrix}$$
Las variables cuantitativas que usaremos son 'consumo_pantalla', el número de horas al día con pantallas abiertas, 'consumo_aplicaciones' y 'consumo_redes' de igual forma con el tiempo dedicado a aplicaciones y a las redes, respectivamente, y, 'horas_act_programadas' que es el total de horas semanales dedicadas a actividades programadas externas al trabajo y a los estudios como pueden ser hacer deporte, clases de teatro, etc.
Como variables ordinales tenemos 'edad' que se divide en cuatro niveles de manera ordenada: 'Niño', 'Joven', 'Adulto' y 'Mayor', la variable 'nivel_estres' con niveles: 'Muy Bajo', 'Bajo', 'Medio', 'Alto', 'Muy Alto' y, como última variable ordinal 'habito_lectura' con los siguientes niveles: 'Nada', 'Poco', 'Regular', 'Frecuente', 'Muy Frecuente'.
Finalmente, como variables nominales estn, por un lado la variable 'dispositivo_usual' con las cuatro siguientes opciones: 'móvil', 'tele', 'tablet', 'PC'; y por otro lado 'max_dedicacion' con una de estas tres opciones: 'lectura', 'deporte' y 'pantallas'. 


```{r, echo=FALSE}
library(MASS)

media <- c(1.3, 1.26, 1.11, 6.5)  # Medias de consumo_pantalla (horas/dia), consumo_aplicaciones (horas/dia), consumo_redes (horas dia), horas_act_programadas (horas/semana)
covarianza <- matrix(c(0.3, 0.08, 0.05, 0.05,
                       0.09, 0.28, 0.03, 0.01,
                       0.08, 0.005, 0.32, 0.01,
                       0.08, 0.38, 0.49, 2), 
                     nrow = 4, ncol = 4)


set.seed(2332)
datos_numericos <- mvrnorm(150, mu = media, Sigma = covarianza)

# Limitar y ajustar valores de las variables según su rango real
datos_numericos[,1] <- pmin(pmax(round(datos_numericos[,1], 2), 0), 24)
datos_numericos[,2] <- pmin(pmax(round(datos_numericos[,2], 2), 0), 24)
datos_numericos[,3] <- pmin(pmax(round(datos_numericos[,3], 2), 0), 24)
datos_numericos[,4] <- pmin(pmax(round(datos_numericos[,4], 2), 0), 168)


# Tabla 1 con los datos 
tiempo_libre <- data.frame(
  consumo_pantalla = round(datos_numericos[,1], 2),
  consumo_aplicaciones = round(datos_numericos[,2], 2),
  consumo_redes = round(datos_numericos[,3], 2),
  horas_ocupado = round(datos_numericos[,4], 2),
  edad = ordered(sample(1:4, 150, replace = TRUE), labels = c("Niño", "Joven", "Adulto", "Mayor")),
  nivel_estres = ordered(sample(1:5, 150, replace = TRUE), labels = c("Muy Bajo", "Bajo", "Medio", "Alto", "Muy Alto")),
  habito_lectura = ordered(sample(1:5, 150, replace = TRUE), labels = c("Nada", "Poco", "Regular", "Frecuente", "Muy Frecuente")),
  dispositivo_usual = sample(c("móvil", "tele", "tablet", "PC"), 150, replace = TRUE),
  max_dedicacion = sample(c("lectura", "deporte", "pantallas"), 150, replace = TRUE)
)


```




# ANÁLISIS DESCRIPTIVO

```{r, echo=FALSE}
a <- tiempo_libre %>%
  dplyr::select( 1:5) %>%
  na.omit

library(GGally)
ggpairs(a)


```
En este gráfico podemos ver como solo destaca cierta correlación entre el tiempo (horas/día) frente a pantallas y el tiempo usado en aplicaciones. Más adelante haremos un test de correlaciones para saber si es o no significativa.

Calculemos, a continuación, la varianza generalizada y la total para obtener más información. La varianza generalizada es el producto de los valores propios de la matriz de covarianzas muestrales $S$. Mientras que la variación total es la suma de los valores propios de la matriz de covarianzas muestrales.

```{r, echo=FALSE}
cuantitativas <- tiempo_libre %>%
  dplyr::select(1:4) %>%
  na.omit

S = cov(cuantitativas)
varianza_generalizada<-prod(eigen(S)$values)
variacion_total<-sum(eigen(S)$values)

```

En este caso, la varianza generalizada tiene un valor de $0.0467$ y la varianza total de $3.1441$. Como la varianza total es mucho más grande que la varianza generalizada (dos ordenes de magnitud), podemos decir que pese a la variación individual que presentan las variables, todas estan fuertemente correlacionadas entre sí lo que podría indicar que hay redundancia entre las variables.

# PRUEBAS ESTADÍSTICAS

Para el cuarto paso elegimos la variable 'max_dedicacion' que representa la actividad que más tiempo consume al indiviuo de entre deporte, lectura o pantallas. Estimaremos los parámetros de esta variable suponiendo que sigue una distribución multinomial. Usaremos la frecuencia relativa para estimar la probabilidad de cada suceso y calcularemos la probabilidad de que de 20 individuos, haya más de seis que prioricen cosas distintas (o le inviertan más tiempo).

```{r, echo=FALSE}
prob = tiempo_libre %>%
  dplyr::select(max_dedicacion) %>%
  count(max_dedicacion) %>%
  mutate(frecuencia_relativa = n/sum(n)) %>%
  dplyr::select(3)

prob = as.matrix(prob)

est_medias = 150 * prob

est_S = 150 * (diag(prob) - prob %*% t(prob))

# Las posibles combinaciones para buscar la probabilidad son:
# 6,7,7 // 7,6,7 // 7,7,6
p_1 = dmultinom(c(6,7,7), prob = prob)
p_2 = dmultinom(c(7,6,7), prob = prob)
p_3 = dmultinom(c(7,7,6), prob = prob)

p = p_1 + p_2 + p_3
p
```
Así, en una muestra de $20$ la probabilidad es de un $10.45$% de que seis o más personas dediquen más tiempo a actividades distintas.

A continuación ajustaremos la variable 'consumo_aplicaciones' repecto a las otras tres variables cuantitativas.


```{r}
Y = cuantitativas$consumo_aplicaciones
X = cuantitativas %>%
  dplyr::select(c(1,3,4))

# Ajustar el modelo de regresión
modelo <- lm(Y ~ ., data = X)
summary(modelo)  # Resumen del modelo
```



Ahora, calculemos la función 'score' de $Y$ con parámetros $\beta_0, \beta_1, \beta_2$ y $\beta_3$. No he podido realizar esta parte puesto que no termino de comprender que es la función score de este modelo. Entiendo que será una matriz $4 \times 1$ con cada componente la parcial respecto a una de las variables pero no de $Y$, sino de $f = log(Y)$ que es más extraño. 
Así, usaremos lo que nos dice internet que relaciona estos dos conceptos a través de la funcón 'predict':

```{r}
predicciones <- predict(modelo, X)

# Cálculo de métricas
mse <- mean((Y - predicciones)^2)
mae <- mean(abs(Y - predicciones))
r2 <- summary(modelo)$r.squared

# Imprimir resultados
cat("MSE:", mse, "\n")
cat("MAE:", mae, "\n")
cat("R²:", r2, "\n")

```
Que parece ser que nos advierten de que el modelo no se ajusta bien a los datos.

Finalmente, para realizar el quinto paso de la entrega, hagamos un contraste de hipótesis para medias entre la variable 'consumo_aplicaciones' y 'consumo_redes':

```{r}
library(Hotelling)

lectores <- tiempo_libre %>%
  filter(max_dedicacion == "lectura") %>%
  dplyr::select(c(1,2,3,4))
adictos <- tiempo_libre %>%
  filter(max_dedicacion == "pantallas") %>%
  dplyr::select(c(1,2,3,4))

resultado <- hotelling.test(lectores, adictos)
print(resultado)
```
Como el p-valor es ligeramnete menor a $0.05$, en este caso existen suficientes evidencias estadísticas como para rechazar la hipótesis de que los vectores de medias son iguales.



# BIBLIOGRAFÍA
Cuadras y los apuntes de mercè e Irene.


























